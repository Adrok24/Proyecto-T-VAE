{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.PRACTICA_GUIADA_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adrok24/Proyecto-Integrador/blob/main/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7tmTNr6KvKB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "55c3e863-98b9-49b2-9c03-bd3fdd515432"
      },
      "source": [
        "!pip install tensorflow-datasets==1.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-datasets==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/34/ff424223ed4331006aaa929efc8360b6459d427063dc59fc7b75d7e4bab3/tensorflow_datasets-1.2.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.22.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (19.3.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (3.10.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (5.4.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.18.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.9.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.3.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (4.41.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==1.2.0) (1.52.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets==1.2.0) (47.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (1.24.3)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "  Found existing installation: tensorflow-datasets 2.1.0\n",
            "    Uninstalling tensorflow-datasets-2.1.0:\n",
            "      Successfully uninstalled tensorflow-datasets-2.1.0\n",
            "Successfully installed tensorflow-datasets-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RBb6cU3gZus"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.random.set_seed(1234)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKBo3_HIgev6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "93b122a3-b106-4f0e-87b6-c94d77d93e44"
      },
      "source": [
        "## Vamos a bajarnos el dataset de dialogos de peliculas de Cornell University\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'cornell_movie_dialogs.zip',\n",
        "    origin=\n",
        "    'http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_dataset = os.path.join(\n",
        "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
        "\n",
        "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
        "path_to_movie_conversations = os.path.join(path_to_dataset,\n",
        "                                           'movie_conversations.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "9920512/9916637 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ4hL2oBHPRL"
      },
      "source": [
        "### Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pke3CJ1qgqd-"
      },
      "source": [
        "# Numero máximo de samples a preprocesar\n",
        "MAX_SAMPLES = 50000\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()\n",
        "  # vamos a crear espacios entre las frases y los puntos:\n",
        "  # ej: \"he is a boy.\" => \"he is a boy .\"\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  # reemplazamos por espacios todo lo que no sea (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence\n",
        "\n",
        "\n",
        "def load_conversations():\n",
        "  id2line = {}\n",
        "  ## levanto las frases\n",
        "  with open(path_to_movie_lines, errors='ignore') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "  ## y me quedo solo con id de frase y texto\n",
        "  for line in lines:\n",
        "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "    id2line[parts[0]] = parts[4]\n",
        "\n",
        "  inputs, outputs = [], []\n",
        "  with open(path_to_movie_conversations, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "  for line in lines:\n",
        "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "    ## me quedo con las conversaciones\n",
        "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
        "\n",
        "    ## nos quedamos con las frases consecutivas: una va a ser usada \n",
        "    ## como \"pregunta\" y la otra como \"respuesta\"\n",
        "    for i in range(len(conversation) - 1):\n",
        "      inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
        "      outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
        "      if len(inputs) >= MAX_SAMPLES:\n",
        "        return inputs, outputs\n",
        "  return inputs, outputs\n",
        "\n",
        "\n",
        "questions, answers = load_conversations()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMlrAY39iLOC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d63ea58c-8f9f-4013-e593-7fb7d576653f"
      },
      "source": [
        "## ejemplo:\n",
        "print(\"Linea 1\")\n",
        "print(questions[0])\n",
        "print(answers[0])\n",
        "print()\n",
        "print(\"Linea 2\")\n",
        "print(questions[1])\n",
        "print(answers[1])\n",
        "print()\n",
        "print(\"Linea 3\")\n",
        "print(questions[2])\n",
        "print(answers[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linea 1\n",
            "can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .\n",
            "well , i thought we d start with pronunciation , if that s okay with you .\n",
            "\n",
            "Linea 2\n",
            "well , i thought we d start with pronunciation , if that s okay with you .\n",
            "not the hacking and gagging and spitting part . please .\n",
            "\n",
            "Linea 3\n",
            "not the hacking and gagging and spitting part . please .\n",
            "okay . . . then how bout we try out some french cuisine . saturday ? night ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oTFeSg4ivYU"
      },
      "source": [
        "## tokenizador de subwords\n",
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    questions + answers, target_vocab_size=2**13)\n",
        "\n",
        "## Recien ahora ponemos los tokens de inicio y fin (sino el tokenizador me los rompe)\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# Le agrego al tamaño del vocab los dos tokens especiales\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s51W5GAHkFyq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "38952b1a-c2c9-4036-9c8e-fc5f9bd6a9a3"
      },
      "source": [
        "## el tokenizador tiene dos metodos: encode y decode:\n",
        "print(tokenizer.encode(\"hello\"))\n",
        "print(tokenizer.decode(tokenizer.encode(\"hello\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[409]\n",
            "hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0FUBYbOjvfC"
      },
      "source": [
        "# Vamos a definir un largo maximo de frase\n",
        "MAX_LENGTH = 50\n",
        "\n",
        "# Tokenizamos, filtramos las secuencias menores al largo maximo\n",
        "# y las paddeamos \n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # tokenizamos + tokens especiales\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "    # filtramos\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # paddeamos\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "\n",
        "\n",
        "questions, answers = tokenize_and_filter(questions, answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUwCqgi8jtZu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7d8475a-b4e9-4212-8421-2c597834fe8c"
      },
      "source": [
        "print('Tamaño vocabulario: {}'.format(VOCAB_SIZE))\n",
        "print('Pares de frases: {}'.format(len(questions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamaño vocabulario: 8333\n",
            "Pares de frases: 46576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFatj3GqupJA"
      },
      "source": [
        "### ver de modificar ESTO\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# saco el token de start de los outputs\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCFUQb58HH9U"
      },
      "source": [
        "### Elementos básicos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWwqmlsovhif"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculamos attention weights \"\"\"\n",
        "\n",
        "  ## hacemos el producto de query por la transpuesta de key\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  ## escalamos por la raiz cuadrado del # dims\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  ## agregamos la mascara\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  ## aplicamos la softmax\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  ## y multiplicamos por value \n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvkNTlcovsvA"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  ''' Vamos a armar la capa para multihead attention '''\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "\n",
        "    ## que es este super?\n",
        "    ## super() te permite acceeder a los metodos de la super clase de la cual\n",
        "    ## la subclase está heredando. En este caso, estas herendando de Layers.\n",
        "        \n",
        "    ## definimos algunos parametros: cuantas cabezas va a tener self attention \n",
        "    ## y la dimensionalidad del embedding\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    ## cuantas dimensiones va a tener cada cabeza:\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    ## vamos a armar la division en cabezas. \n",
        "    ## se va a entender mejor en el siguiente bloque de codigo\n",
        "    ## por ahora es solamente la forma en la que \n",
        "    ## reacomodamos los datos para armar las cabezas\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    ''' Este call es el metodo que  va a llamar keras para usar la capa'''\n",
        "\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    # acomodamos las dimensiones\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenamos las cabezas\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxWsmzF8vy0O"
      },
      "source": [
        "## creamos una mascara para el padding (asi nos nos molesta)\n",
        "## con esto lo que hacemos es despues pasarselo a la capa \n",
        "## anterior y eliminamos los paddings\n",
        "\n",
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytRdpjhXvzV4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0161fcd5-8d9e-40ac-9145-7ce6413933a8"
      },
      "source": [
        "## vamos a mostrar como funciona:\n",
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7lli_1fv2Gg"
      },
      "source": [
        "## vamos a crear la otra mascara:\n",
        "## ahora queremos la mascara para no ver el futuro\n",
        "## vamos a incorporarle tambien la mascara para el padding\n",
        "\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "\n",
        "  ## aca la mascara para el padding\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UgSY2_nwMNt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7725e764-1602-4ef7-e71e-d02f681373a4"
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2,3, 0,4, 0]])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 0. 1.]\n",
            "   [0. 0. 0. 1. 0. 1.]]]], shape=(1, 1, 6, 6), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HztpT3O63TIg"
      },
      "source": [
        "a = tf.constant([2,4,6])\n",
        "b = tf.constant([1,3,5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kV-RpKz3YYi"
      },
      "source": [
        "c= tf.concat([b,a],axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXvoowMLwNZR"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  ''' Armamos los encodings de posición '''\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  ## comparar con formula de la teorica\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "   \n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # seno a los indices pares\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # coseno a los impares\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, :]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYT57O5kJeKT"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is6EC55bwwAG"
      },
      "source": [
        "## ya tenemos todos los ingredientes para armar una capa de encoder\n",
        "## todavía no es el encoder entero!\n",
        "\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX5a3YBl5XsG"
      },
      "source": [
        "## ahora si: el encoder\n",
        "## vamos a definir una funcion que nos devuelva un modelo que tenga\n",
        "## num_layers bloques de encoder:\n",
        "\n",
        "def encoder(vocab_size, num_layers, units, d_model, num_heads,\n",
        "            dropout, name=\"encoder\"):\n",
        "  \n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  ## partimos de los embeddings\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  ## y les sumamos el positional encoding\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  ## y usamos tantos bloques como querramos\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "                            units=units,\n",
        "                            d_model=d_model,\n",
        "                            num_heads=num_heads,\n",
        "                            dropout=dropout,\n",
        "                            name=\"encoder_layer_{}\".format(i),\n",
        "                        )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq48-SRsG8UA"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avimnpJTRvFn"
      },
      "source": [
        "## vamos a usar las mismas partes que ya tenemos para armar el decoder\n",
        "## primero la decoder layer\n",
        "\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  \n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUUvWeK6HWqP"
      },
      "source": [
        "## y ahora usamos la decoder layer para el decoder\n",
        "\n",
        "def decoder(vocab_size, num_layers, units, d_model, num_heads,\n",
        "            dropout, name='decoder'):\n",
        "    \n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  \n",
        "  ## la mascara para no ver el futuro y para el padding\n",
        "  ## ojo que la toma de afuera (es un input, no la creamos aca)\n",
        "\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  ## embeddings\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  ## vamos a tener num_layers bloques de decoders\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFj1enIjIDs8"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E61hsHWrIL4H"
      },
      "source": [
        "def transformer(vocab_size, num_layers, units, d_model, num_heads,\n",
        "                dropout, name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # vamos a pasar las funciones que arman las mascaras en forma de capas\n",
        "  # la lookahead\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # mascara de padding\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # instanciamos el encoder y le pasamos el input y la mask\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # lo que sale del encoder lo pasamos al decoder\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7CP0KswNS-m"
      },
      "source": [
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJFhekuVH-2o"
      },
      "source": [
        "## en los ejemplos anteriores maskeamos los 0 desde el embedding\n",
        "## acá no tenemos eso, así que tenemos que tocar la función de perdida\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  ## calculamos la loss sin reducir\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  ## aplicamos una mascara\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  ## y reducimos la loss\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrPaA7nNQN73"
      },
      "source": [
        "## nos queda armar el lr que va cambiando con el tiempo\n",
        "## hay que hacer un schedule de lr:\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "\n",
        "    '''  Comparar con la formula de la teorica '''\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWRMqA1lQ6CG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "cbbba308-5dab-4bd0-983b-9b0eb9244032"
      },
      "source": [
        "## veamos que pinta tiene\n",
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJvle4mJRBf_"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqgVoM9ERQnh"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # me aseguro que la forma esté bien\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8E54hfUWNRT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "716d50ed-e87e-4ee8-a846-90f08d5df4dd"
      },
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "728/728 [==============================] - 70s 96ms/step - loss: 1.7854 - accuracy: 0.0362\n",
            "Epoch 2/20\n",
            "728/728 [==============================] - 69s 95ms/step - loss: 1.2803 - accuracy: 0.0653\n",
            "Epoch 3/20\n",
            "728/728 [==============================] - 69s 94ms/step - loss: 1.1951 - accuracy: 0.0713\n",
            "Epoch 4/20\n",
            "728/728 [==============================] - 68s 93ms/step - loss: 1.1448 - accuracy: 0.0752\n",
            "Epoch 5/20\n",
            "728/728 [==============================] - 68s 93ms/step - loss: 1.1008 - accuracy: 0.0786\n",
            "Epoch 6/20\n",
            "728/728 [==============================] - 67s 93ms/step - loss: 1.0602 - accuracy: 0.0814\n",
            "Epoch 7/20\n",
            "728/728 [==============================] - 67s 93ms/step - loss: 1.0112 - accuracy: 0.0852\n",
            "Epoch 8/20\n",
            "728/728 [==============================] - 68s 93ms/step - loss: 0.9617 - accuracy: 0.0895\n",
            "Epoch 9/20\n",
            "728/728 [==============================] - 67s 92ms/step - loss: 0.9159 - accuracy: 0.0940\n",
            "Epoch 10/20\n",
            "728/728 [==============================] - 68s 93ms/step - loss: 0.8741 - accuracy: 0.0984\n",
            "Epoch 11/20\n",
            "728/728 [==============================] - 67s 92ms/step - loss: 0.8362 - accuracy: 0.1027\n",
            "Epoch 12/20\n",
            "728/728 [==============================] - 67s 92ms/step - loss: 0.8004 - accuracy: 0.1074\n",
            "Epoch 13/20\n",
            "728/728 [==============================] - 67s 93ms/step - loss: 0.7696 - accuracy: 0.1114\n",
            "Epoch 14/20\n",
            "728/728 [==============================] - 68s 93ms/step - loss: 0.7404 - accuracy: 0.1155\n",
            "Epoch 15/20\n",
            "728/728 [==============================] - 67s 92ms/step - loss: 0.7138 - accuracy: 0.1193\n",
            "Epoch 16/20\n",
            "728/728 [==============================] - 67s 92ms/step - loss: 0.6887 - accuracy: 0.1233\n",
            "Epoch 17/20\n",
            "728/728 [==============================] - 67s 92ms/step - loss: 0.6679 - accuracy: 0.1265\n",
            "Epoch 18/20\n",
            "728/728 [==============================] - 67s 92ms/step - loss: 0.6465 - accuracy: 0.1298\n",
            "Epoch 19/20\n",
            "728/728 [==============================] - 68s 93ms/step - loss: 0.6279 - accuracy: 0.1330\n",
            "Epoch 20/20\n",
            "728/728 [==============================] - 68s 93ms/step - loss: 0.6111 - accuracy: 0.1358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcdd15d0f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L60Inkf6VUwi"
      },
      "source": [
        "## Testeamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3Ra213yjvrW"
      },
      "source": [
        "## definimos dos funciones. Una para ir sacando las predicciones\n",
        "## la segunda para traducir de vuelta de numero a ingles\n",
        "\n",
        "def evaluate(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output])\n",
        "\n",
        "    # tomamos la ultima palabra\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # y si llegamos al token de finalizacion, paramos\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # concatenamos\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M31k9WuQnuI9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6451789f-e53d-4a1b-b03d-af4a557986a3"
      },
      "source": [
        "predict(\"Hello.\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: Hello.\n",
            "Output: i m sorry . i m sorry . i m sorry . you ve been acting strangely , and i have to see you .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i m sorry . i m sorry . i m sorry . you ve been acting strangely , and i have to see you .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G5-LtMWn6Ks"
      },
      "source": [
        "## Conozco gente así.\n",
        "## Podríamos entrenar con mas texto o por mas tiempo y ver resultados distintos"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}